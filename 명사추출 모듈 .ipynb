{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3-52\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모듈 만들기 \n",
    "def df_review(filepath):\n",
    "    #파일다듬기 \n",
    "    f = open(filepath, 'r')\n",
    "    review_raw = f.read()\n",
    "    f.close()\n",
    "    review_raw_split=review_raw.split(\"\\n\")\n",
    "    \n",
    "    # 명사 top 100추출\n",
    "    result =[]\n",
    "    for i in review_raw_split:\n",
    "        nouns = twitter.nouns(i)\n",
    "        nouns_nltk = nltk.Text(nouns, name ='리뷰')\n",
    "        result.append(nouns_nltk.vocab().most_common(100))\n",
    "    \n",
    "    #n개 영화 noun_count 뽑아서 저장\n",
    "    review_nouns_count= []\n",
    "    j = 0\n",
    "    for i in result: \n",
    "        review_nouns_count.append(i)\n",
    "        print(\"{}번째 영화의 형태수 빈도수를 추출중입니다\".format(j))\n",
    "        j+=1\n",
    "    \n",
    "    #데이터프레임화해서 저장\n",
    "    df = pd.DataFrame({\"명사_숫자\":review_nouns_count})\n",
    "    df.to_csv(\"df_review.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 영화의 형태수 빈도수를 추출중입니다\n",
      "1번째 영화의 형태수 빈도수를 추출중입니다\n",
      "2번째 영화의 형태수 빈도수를 추출중입니다\n",
      "3번째 영화의 형태수 빈도수를 추출중입니다\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>명사_숫자</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(제목, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(편, 2261), (영화, 1749), (주지훈, 779), (더, 752), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(영화, 3138), (감동, 986), (눈물, 789), (연기, 736), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               명사_숫자\n",
       "0                                          [(제목, 1)]\n",
       "1  [(편, 2261), (영화, 1749), (주지훈, 779), (더, 752), ...\n",
       "2  [(영화, 3138), (감동, 986), (눈물, 789), (연기, 736), ...\n",
       "3                                                 []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'allreviews_plusname_test.csv'\n",
    "f = open(filepath, 'r')\n",
    "review_raw = f.read()\n",
    "f.close()\n",
    "review_raw_split=review_raw.split(\"\\n\")\n",
    "    \n",
    "    # 명사 top 100추출\n",
    "result =[]\n",
    "for i in review_raw_split:\n",
    "    nouns = twitter.nouns(i)\n",
    "    nouns_nltk = nltk.Text(nouns, name ='리뷰')\n",
    "    result.append(nouns_nltk.vocab().most_common(100))\n",
    "    \n",
    "    #n개 영화 noun_count 뽑아서 저장\n",
    "review_nouns_count= []\n",
    "j = 0\n",
    "for i in result: \n",
    "    review_nouns_count.append(i)\n",
    "    print(\"{}번째 영화의 형태수 빈도수를 추출중입니다\".format(j))\n",
    "    j+=1\n",
    "    \n",
    "    #데이터프레임화해서 저장\n",
    "df = pd.DataFrame({\"명사_숫자\":review_nouns_count})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 영화의 형태수 빈도수를 추출중입니다\n",
      "1번째 영화의 형태수 빈도수를 추출중입니다\n",
      "2번째 영화의 형태수 빈도수를 추출중입니다\n",
      "3번째 영화의 형태수 빈도수를 추출중입니다\n",
      "                                               명사_숫자\n",
      "0                                          [(제목, 1)]\n",
      "1  [(편, 2261), (영화, 1749), (주지훈, 779), (더, 752), ...\n",
      "2  [(영화, 3138), (감동, 986), (눈물, 789), (연기, 736), ...\n",
      "3                                                 []\n"
     ]
    }
   ],
   "source": [
    "filepath = 'allreviews_plusname_test.csv'\n",
    "df_review(filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-> 테스팅 이후 모듈화하는 작업이 매우 중요하다\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def getKowikiInfos(filepath):\n",
    "    with open(filepath, encoding='utf-8') as fp:\n",
    "        soup = BeautifulSoup(fp, 'lxml')\n",
    "    Updates  = []\n",
    "    Title    = []\n",
    "    FileList = []   # 파일이름 리스트 : files는 다양하고 긴 정보가 들어있으니까 간단히 보여주도록 하나 더 만들어줌 \n",
    "    Files    = []   # 파일상세 리스트\n",
    "    done_tags = soup.find_all('li', 'done')\n",
    "\n",
    "    for done_tag in done_tags:\n",
    "        # 등록날짜\n",
    "        updates = done_tag.find('span', 'updates').get_text()\n",
    "        # 제목\n",
    "        title = done_tag.find('span', 'title').get_text()\n",
    "        # 파일리스트\n",
    "        file_tags = done_tag.find_all('li', 'file')\n",
    "        files = []\n",
    "        filenames = []\n",
    "        for file_tag in file_tags:\n",
    "            file_dict = {}\n",
    "            file_name = file_tag.find('a').get_text()\n",
    "            file_link = file_tag.find('a').get('href')\n",
    "\n",
    "            file_dict['FileName'] = file_name\n",
    "            file_dict['FileLink'] = file_link\n",
    "            #딕셔너리append\n",
    "            files.append(file_dict)\n",
    "            #파일네임만 리스트로 append\n",
    "            filenames.append(file_name)\n",
    "\n",
    "        #리턴값들\n",
    "        Updates.append(updates)\n",
    "        Title.append(title)\n",
    "        #튜플타입으로 묶어버림\n",
    "        FileList.append(tuple(filenames))\n",
    "        Files.append(files)\n",
    "\n",
    "    #데이터프레임으로 리턴 \n",
    "    kokiwi_df = pd.DataFrame({ 'Updates'  : Updates, \n",
    "                               'Title'    : Title,\n",
    "                               'FileList' : FileList,\n",
    "                               'FileInfo' : Files }, \n",
    "                               columns = ['Updates', 'Title', 'FileList', 'FileInfo'])\n",
    "\n",
    "    return kokiwi_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
